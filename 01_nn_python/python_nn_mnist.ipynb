{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 使用纯Python实现的神经网络训练MNIST数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0.a结构图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![神经网络结构图](./nn.png \"神经网络结构图\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0.b公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- 前传：\n",
    "$\\begin{eqnarray*}\n",
    "\\left\\{\\begin{aligned}\n",
    "& \\alpha_h = \\sum_{i=1}^{d}w_{ih}x_i + b_h \\\\\n",
    "& a_h = \\sigma{(\\alpha_h)} \\\\\n",
    "& \\beta_j = \\sum_{h=1}^{q}w_{hj}a_h + b_j \\\\\n",
    "& \\hat{y_j} = \\sigma{(\\beta_j)} \\\\\n",
    "& c_i = \\frac{1}{2}(\\hat{y_i}-y_i)^{2}\n",
    "\\end{aligned}\\right.\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "- 反传：\n",
    "$\\begin{eqnarray*}\n",
    "\\left\\{\\begin{aligned}\n",
    "& \\delta = \\frac{\\partial c_j}{\\partial \\beta_j} = (\\hat{y_i}-y_i)\\sigma^{'}{(\\beta_j)}\\\\\n",
    "& \\Delta{b_j} = -\\eta \\frac{\\partial c_j}{\\partial b_j} = -\\eta \\frac{\\partial c_j}{\\partial \\beta_j} \\frac{\\partial \\beta_j}{\\partial b_j} = -\\eta \\delta\\\\\n",
    "& \\Delta{w_{hj}} = -\\eta \\frac{\\partial c_j}{\\partial w_j} = -\\eta \\frac{\\partial c_j}{\\partial \\beta_j} \\frac{\\partial \\beta_j}{\\partial w_j} = -\\eta \\delta a_h \\\\\n",
    "& \\Delta{b_h} = -\\eta \\frac{\\partial c_j}{\\partial a_h} \\frac{\\partial a_h}{\\partial \\alpha_h} \\frac{\\partial \\alpha_h}{\\partial b_h} = -\\eta \\frac{\\partial c_j}{\\partial \\beta_j} \\frac{\\partial \\beta_j}{\\partial a_h} \\frac{\\partial a_h}{\\partial \\alpha_h} \\frac{\\partial \\alpha_h}{\\partial b_h} = -\\eta \\delta w_{hj} \\sigma^{'}{(\\alpha_h)} \\\\\n",
    "& \\Delta{w_{ih}} = -\\eta \\frac{\\partial c_j}{\\partial a_h} \\frac{\\partial a_h}{\\partial \\alpha_h} \\frac{\\partial \\alpha_h}{\\partial w_{ih}} = -\\eta \\frac{\\partial c_j}{\\partial \\beta_j} \\frac{\\partial \\beta_j}{\\partial a_h} \\frac{\\partial a_h}{\\partial \\alpha_h} \\frac{\\partial \\alpha_h}{\\partial w_{ih}} = -\\eta \\delta w_{hj} \\sigma^{'}{(\\alpha_h)}x_i\n",
    "\\end{aligned}\\right.\n",
    "\\end{eqnarray*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    \n",
    "    # 初始化神经网络，sizes是每层的神经元个数,len(sizes)神经网络的层数\n",
    "    def __init__(self, sizes, activation='sigmoid'):\n",
    "        self.sizes_     = sizes\n",
    "        self.num_layers_ = len(sizes)\n",
    "        self.w_ = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.b_ = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        \n",
    "        self.activate = self.sigmoid if activation == 'sigmoid' else self.tanh\n",
    "        self.activate_prime = self.sigmoid_prime if activation == 'sigmoid' else self.tanh_prime\n",
    "    \n",
    "    # Sigmoid函数，S型曲线，\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    # Sigmoid函数的导函数\n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    # tanh函数，S型曲线\n",
    "    def tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    # tanh函数的导函数\n",
    "    def tanh_prime(self, z):\n",
    "        return 1 - np.tanh(z)**2\n",
    " \n",
    "    # 目标函数（cost=1/2*(y_predict - y_real)**2）的导函数（cost_derivative=y_predict - y_real）\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations-y)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        for b, w in zip(self.b_, self.w_):\n",
    "            x = self.sigmoid(np.dot(w, x)+b)\n",
    "        return x\n",
    " \n",
    "    def backprop(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.b_]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.w_]\n",
    " \n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for b, w in zip(self.b_, self.w_):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = self.activate(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        delta = self.cost_derivative(activations[-1], y) * self.activate_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    " \n",
    "        for l in range(2, self.num_layers_):\n",
    "            z = zs[-l]\n",
    "            sp = self.activate_prime(z)\n",
    "            delta = np.dot(self.w_[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    " \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.b_]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.w_]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.w_ = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.w_, nabla_w)]\n",
    "        self.b_ = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.b_, nabla_b)]\n",
    " \n",
    "    # training_data是训练数据(x, y);epochs是训练次数;mini_batch_size是每次训练样本数;eta是learning rate\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    " \n",
    "        n = len(training_data)\n",
    "        for j in  range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))\n",
    " \n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    " \n",
    "    # 预测\n",
    "    def predict(self, data):\n",
    "        value = self.feedforward(data)\n",
    "        return value.tolist().index(max(value))\n",
    " \n",
    "    # 保存训练模型\n",
    "    def save(self):\n",
    "        pass  # 把_w和_b保存到文件(pickle)\n",
    "    def load(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# http://g.sweyla.com/blog/2012/mnist-numpy/\n",
    "import os, struct\n",
    "import numpy as np\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    " \n",
    "def load_mnist(dataset=\"training_data\", digits=np.arange(10), path=\".\"):\n",
    "\n",
    "    if dataset == \"training_data\":\n",
    "        fname_image = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_label = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing_data\":\n",
    "        fname_image = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_label = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'training_data' or 'testing_data'\")\n",
    "    \n",
    "    flbl = open(fname_label, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_image, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def load_samples(dataset=\"training_data\"):\n",
    "    image,label = load_mnist(dataset)\n",
    "    #print(image[0].shape, image.shape)   # (28, 28) (60000, 28, 28)\n",
    "    #print(label[0].shape, label.shape)   # (1,) (60000, 1)\n",
    "    #print(label[0])   # 5\n",
    " \n",
    "    # 把28*28二维数据转为一维数据\n",
    "    X = [np.reshape(x,(28*28, 1)) for x in image]\n",
    "    X = [x/255.0 for x in X]   # 灰度值范围(0-255)，转换为(0-1)\n",
    "    #print(X.shape)\n",
    "    \n",
    "        # 5 -> [0,0,0,0,0,1.0,0,0,0];  1 -> [0,1.0,0,0,0,0,0,0,0]\n",
    "    def vectorized_Y(y): \n",
    "        e = np.zeros((10, 1))\n",
    "        e[y] = 1.0\n",
    "        return e\n",
    "\n",
    "    if dataset == \"training_data\":\n",
    "        Y = [vectorized_Y(y) for y in label]\n",
    "        pair = list(zip(X, Y))\n",
    "        return pair\n",
    "\n",
    "    elif dataset == 'testing_data':\n",
    "        pair = list(zip(X, label))\n",
    "        return pair\n",
    "    else:\n",
    "        print('Something wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 5993 / 10000\n",
      "Epoch 1: 7429 / 10000\n",
      "Epoch 2: 8534 / 10000\n",
      "Epoch 3: 8792 / 10000\n",
      "Epoch 4: 8925 / 10000\n",
      "Epoch 5: 8995 / 10000\n",
      "Epoch 6: 9056 / 10000\n",
      "Epoch 7: 9081 / 10000\n",
      "Epoch 8: 9124 / 10000\n",
      "Epoch 9: 9137 / 10000\n",
      "Epoch 10: 9171 / 10000\n",
      "Epoch 11: 9172 / 10000\n",
      "Epoch 12: 9190 / 10000\n",
      "准确率:  0.919\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    INPUT = 28*28\n",
    "    OUTPUT = 10\n",
    "    net = NeuralNet([INPUT, 28, OUTPUT], activation='sigmoid')\n",
    "\n",
    "    train_set = load_samples(dataset='training_data')\n",
    "    test_set = load_samples(dataset='testing_data')\n",
    "\n",
    "    net.SGD(train_set, 13, 100, 3.0, test_data=test_set)\n",
    "\n",
    "    #准确率\n",
    "    correct = 0;\n",
    "    for test_feature in test_set:\n",
    "        if net.predict(test_feature[0]) == test_feature[1][0]:\n",
    "            correct += 1\n",
    "    print \"准确率: \", correct*1.0/len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "finish, amount 9912422 bytes!\n",
      "downloading: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "finish, amount 28881 bytes!\n",
      "downloading: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "finish, amount 1648877 bytes!\n",
      "downloading: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "finish, amount 4542 bytes!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import gzip\n",
    "import urllib2\n",
    "\n",
    "names = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
    "urls  = ['http://yann.lecun.com/exdb/mnist/'+name for name in names]\n",
    "for url, name in zip(urls, names):\n",
    "    print 'downloading:',url\n",
    "    open(name, 'wb').write(urllib2.urlopen(url).read())\n",
    "    print 'finish, amount {} bytes!'.format(os.path.getsize(name))\n",
    "    \n",
    "    # print 'decompress {}'.format(name)\n",
    "    # open(name[:-3], 'wb').write(gzip.zlib.decompress(name))\n",
    "    # print 'finish.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 解压：\n",
    "\n",
    "```shell\n",
    "$ls | grep gz | xargs gzip -d\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
