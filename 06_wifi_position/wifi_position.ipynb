{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 基于AutoEncoder训练wifi指纹的室内定位系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```shell\n",
    "    wget https://archive.ics.uci.edu/ml/machine-learning-databases/00310/UJIndoorLoc.zip\n",
    "    unzip UJIndoorLoc.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "train_data = pd.read_csv('UJIndoorLoc/trainingData.csv', header=0)\n",
    "test_data  = pd.read_csv('UJIndoorLoc/validationData.csv', header=0)\n",
    "\n",
    "train_data.head()\n",
    "# test_data.head()\n",
    "train_x = scale(np.asarray(train_data.ix[:, 0:520]))\n",
    "train_y = np.asarray(train_data['BUILDINGID'].map(str) + train_data['FLOOR'].map(str))\n",
    "train_y = np.asarray(pd.get_dummies(train_y))\n",
    "\n",
    "test_x = scale(np.asarray(test_data.ix[:, 0:520]))\n",
    "test_y = np.asarray(test_data['BUILDINGID'].map(str) + test_data['FLOOR'].map(str))\n",
    "test_y = np.asarray(pd.get_dummies(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.使用AutoEncoder网络训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1.引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2.定义网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size  = train_x.shape[1]\n",
    "num_classes = train_y.shape[1]\n",
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "Encoders = [(input_size, 256), (256, 128), (128, 64)]\n",
    "Decoders = [(64, 128), (128, 256), (256, 520)]\n",
    "dnns     = [(64, 128), (128, 128), (128, num_classes)]\n",
    "\n",
    "epoch = 30\n",
    "batch_size = 10\n",
    "batch_nums = train_x.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=[shape]))\n",
    "\n",
    "def AutoEncoder(x):\n",
    "    # Encoder\n",
    "    encoder_output = x\n",
    "    for idx, shape in enumerate(Encoders):\n",
    "        with tf.name_scope('encoder_%d' % idx):\n",
    "            w = weight_variable(shape)\n",
    "            b = bias_variable(shape[-1])\n",
    "            encoder_output = tf.tanh(tf.add(tf.matmul(encoder_output, w), b))\n",
    "    \n",
    "    # Decoder \n",
    "    o_decoder = encoder_output\n",
    "    for idx, shape in enumerate(Decoders):\n",
    "        with tf.name_scope('decoder_%d' % idx):\n",
    "            w = weight_variable(shape)\n",
    "            b = bias_variable(shape[-1])\n",
    "            o_decoder = tf.tanh(tf.add(tf.matmul(o_decoder, w), b))\n",
    "    decoder_output = o_decoder\n",
    "    \n",
    "    # DNN\n",
    "    o_dnn = encoder_output\n",
    "    for idx, shape in enumerate(dnns):\n",
    "        with tf.name_scope('dnn_%d' % idx):\n",
    "            w = weight_variable(shape)\n",
    "            b = bias_variable(shape[-1])\n",
    "            o_dnn = tf.tanh(tf.add(tf.matmul(o_dnn, w), b))\n",
    "    dnn_output = tf.nn.softmax(o_dnn)\n",
    "    \n",
    "    return decoder_output, dnn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3.训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In AutoEncoder, Epoch 1/30--Loss:0.954828560352\n",
      "In AutoEncoder, Epoch 2/30--Loss:0.871471881866\n",
      "In AutoEncoder, Epoch 3/30--Loss:0.831469833851\n",
      "In AutoEncoder, Epoch 4/30--Loss:0.809065341949\n",
      "In AutoEncoder, Epoch 5/30--Loss:0.794841885567\n",
      "In AutoEncoder, Epoch 6/30--Loss:0.784694254398\n",
      "In AutoEncoder, Epoch 7/30--Loss:0.776862323284\n",
      "In AutoEncoder, Epoch 8/30--Loss:0.770530581474\n",
      "In AutoEncoder, Epoch 9/30--Loss:0.76526671648\n",
      "In AutoEncoder, Epoch 10/30--Loss:0.760809540749\n",
      "In AutoEncoder, Epoch 11/30--Loss:0.756984472275\n",
      "In AutoEncoder, Epoch 12/30--Loss:0.753665030003\n",
      "In AutoEncoder, Epoch 13/30--Loss:0.750754833221\n",
      "In AutoEncoder, Epoch 14/30--Loss:0.748178303242\n",
      "In AutoEncoder, Epoch 15/30--Loss:0.745875239372\n",
      "In AutoEncoder, Epoch 16/30--Loss:0.74379837513\n",
      "In AutoEncoder, Epoch 17/30--Loss:0.74190980196\n",
      "In AutoEncoder, Epoch 18/30--Loss:0.740180075169\n",
      "In AutoEncoder, Epoch 19/30--Loss:0.738585531712\n",
      "In AutoEncoder, Epoch 20/30--Loss:0.737107396126\n",
      "In AutoEncoder, Epoch 21/30--Loss:0.735730648041\n",
      "In AutoEncoder, Epoch 22/30--Loss:0.7344430089\n",
      "In AutoEncoder, Epoch 23/30--Loss:0.733234524727\n",
      "In AutoEncoder, Epoch 24/30--Loss:0.732097029686\n",
      "In AutoEncoder, Epoch 25/30--Loss:0.731023311615\n",
      "In AutoEncoder, Epoch 26/30--Loss:0.730007469654\n",
      "In AutoEncoder, Epoch 27/30--Loss:0.729044437408\n",
      "In AutoEncoder, Epoch 28/30--Loss:0.728130042553\n",
      "In AutoEncoder, Epoch 29/30--Loss:0.727260351181\n",
      "In AutoEncoder, Epoch 30/30--Loss:0.726432025433\n",
      "In DNN, Epoch 1/30--Loss:14.4849510193--Train Accuracy:0.327381253242--Test Accuracy:0.226822689176\n",
      "In DNN, Epoch 2/30--Loss:13.2353610992--Train Accuracy:0.414906948805--Test Accuracy:0.332133203745\n",
      "In DNN, Epoch 3/30--Loss:12.1661911011--Train Accuracy:0.50980591774--Test Accuracy:0.38343834877\n",
      "In DNN, Epoch 4/30--Loss:11.5718412399--Train Accuracy:0.640016078949--Test Accuracy:0.54545456171\n",
      "In DNN, Epoch 5/30--Loss:10.9012460709--Train Accuracy:0.671063840389--Test Accuracy:0.630963087082\n",
      "In DNN, Epoch 6/30--Loss:10.6890964508--Train Accuracy:0.675427615643--Test Accuracy:0.624662458897\n",
      "In DNN, Epoch 7/30--Loss:10.5469245911--Train Accuracy:0.694788575172--Test Accuracy:0.646264612675\n",
      "In DNN, Epoch 8/30--Loss:10.4562339783--Train Accuracy:0.72056978941--Test Accuracy:0.645364522934\n",
      "In DNN, Epoch 9/30--Loss:10.3629398346--Train Accuracy:0.760595858097--Test Accuracy:0.660666048527\n",
      "In DNN, Epoch 10/30--Loss:10.3956108093--Train Accuracy:0.745247542858--Test Accuracy:0.639963984489\n",
      "In DNN, Epoch 11/30--Loss:10.366686821--Train Accuracy:0.712745130062--Test Accuracy:0.646264612675\n",
      "In DNN, Epoch 12/30--Loss:10.3217201233--Train Accuracy:0.743542134762--Test Accuracy:0.641764163971\n",
      "In DNN, Epoch 13/30--Loss:10.2662067413--Train Accuracy:0.758890509605--Test Accuracy:0.678667843342\n",
      "In DNN, Epoch 14/30--Loss:10.2787532806--Train Accuracy:0.775342345238--Test Accuracy:0.667866766453\n",
      "In DNN, Epoch 15/30--Loss:10.2316646576--Train Accuracy:0.760244786739--Test Accuracy:0.661566138268\n",
      "In DNN, Epoch 16/30--Loss:10.2146654129--Train Accuracy:0.788283109665--Test Accuracy:0.673267304897\n",
      "In DNN, Epoch 17/30--Loss:10.3115882874--Train Accuracy:0.775843918324--Test Accuracy:0.650765061378\n",
      "In DNN, Epoch 18/30--Loss:10.2663068771--Train Accuracy:0.81326174736--Test Accuracy:0.657065689564\n",
      "In DNN, Epoch 19/30--Loss:10.2080259323--Train Accuracy:0.806490421295--Test Accuracy:0.666966676712\n",
      "In DNN, Epoch 20/30--Loss:10.1911478043--Train Accuracy:0.811757028103--Test Accuracy:0.670567035675\n",
      "In DNN, Epoch 21/30--Loss:10.1934776306--Train Accuracy:0.826403141022--Test Accuracy:0.673267304897\n",
      "In DNN, Epoch 22/30--Loss:10.1783456802--Train Accuracy:0.822390556335--Test Accuracy:0.648964881897\n",
      "In DNN, Epoch 23/30--Loss:10.1867799759--Train Accuracy:0.841049313545--Test Accuracy:0.677767753601\n",
      "In DNN, Epoch 24/30--Loss:10.1716451645--Train Accuracy:0.812760174274--Test Accuracy:0.663366317749\n",
      "In DNN, Epoch 25/30--Loss:10.1804618835--Train Accuracy:0.804785072803--Test Accuracy:0.659765958786\n",
      "In DNN, Epoch 26/30--Loss:10.1722736359--Train Accuracy:0.832121193409--Test Accuracy:0.670567035675\n",
      "In DNN, Epoch 27/30--Loss:10.1287002563--Train Accuracy:0.840748369694--Test Accuracy:0.678667843342\n",
      "In DNN, Epoch 28/30--Loss:10.1326990128--Train Accuracy:0.846616864204--Test Accuracy:0.678667843342\n",
      "In DNN, Epoch 29/30--Loss:10.1387367249--Train Accuracy:0.824497163296--Test Accuracy:0.650765061378\n",
      "In DNN, Epoch 30/30--Loss:10.2084636688--Train Accuracy:0.839945852757--Test Accuracy:0.682268202305\n"
     ]
    }
   ],
   "source": [
    "def train(x, y):\n",
    "    decoder_output, dnn_output = AutoEncoder(x)\n",
    "    \n",
    "    decoder_cost = tf.reduce_mean(tf.pow(x - decoder_output, 2))\n",
    "    decoder_opti = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(decoder_cost)\n",
    "    \n",
    "    dnn_cost     = - tf.reduce_sum(y*tf.log(dnn_output))\n",
    "    dnn_opti     = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(dnn_cost)\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(dnn_output, 1), tf.argmax(y, 1))\n",
    "    accuracy     = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 1.we first train the autoencoder\n",
    "    for e in range(epoch):\n",
    "        epoch_loss = []\n",
    "        for batch in range(batch_nums):\n",
    "            start, end = batch*batch_size, (batch+1)*batch_size\n",
    "            batch_x, batch_y = train_x[start:end, :], train_y[start:end, :]\n",
    "            c, _ = sess.run([decoder_cost, decoder_opti], feed_dict={X: batch_x, Y: batch_y})\n",
    "            epoch_loss.append(c)\n",
    "        print 'In AutoEncoder, Epoch {}/{}--Loss:{}'.format(e+1, epoch, np.mean(epoch_loss))\n",
    "    \n",
    "    # 2.we train dnn next\n",
    "    for e in range(epoch):\n",
    "        epoch_loss = []\n",
    "        for batch in range(batch_nums):\n",
    "            start, end = batch*batch_size, (batch+1)*batch_size\n",
    "            batch_x, batch_y = train_x[start:end, :], train_y[start:end, :]\n",
    "            c, _ = sess.run([dnn_cost, dnn_opti], feed_dict={X: batch_x, Y: batch_y})\n",
    "            epoch_loss.append(c)\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={X: train_x, Y: train_y})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_x, Y: test_y})\n",
    "        print 'In DNN, Epoch {}/{}--Loss:{}--Train Accuracy:{}--Test Accuracy:{}'.format(e+1, epoch, np.mean(epoch_loss), train_accuracy, test_accuracy)\n",
    "        \n",
    "train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
